{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representation Similarity in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document author: Youngbin-Ro (youngbin_ro@korea.ac.kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementation in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_linear(x):\n",
    "    \"\"\"Compute Gram (kernel) matrix for a linear kernel.\n",
    "\n",
    "    Args:\n",
    "        x: A num_examples x num_features matrix of features.\n",
    "\n",
    "    Returns:\n",
    "        A num_examples x num_examples Gram matrix of examples.\n",
    "    \"\"\"\n",
    "    return x.dot(x.T)\n",
    "\n",
    "\n",
    "def gram_linear_tf(x):\n",
    "    \"\"\"tensorflow version of gram_linear\"\"\"\n",
    "    return tf.matmul(x, tf.transpose(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sameness\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "X_tf = tf.constant(X)\n",
    "\n",
    "gram_X = gram_linear(X)\n",
    "gram_X_tf = gram_linear_tf(X_tf).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(gram_X, gram_X_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_rbf(x, threshold=1.0):\n",
    "    \"\"\"Compute Gram (kernel) matrix for an RBF kernel.\n",
    "\n",
    "    Args:\n",
    "        x: A num_examples x num_features matrix of features.\n",
    "        threshold: Fraction of median Euclidean distance to use as RBF kernel\n",
    "        bandwidth. (This is the heuristic we use in the paper. There are other\n",
    "        possible ways to set the bandwidth; we didn't try them.)\n",
    "\n",
    "    Returns:\n",
    "        A num_examples x num_examples Gram matrix of examples.\n",
    "    \"\"\"\n",
    "    dot_products = x.dot(x.T)\n",
    "    sq_norms = np.diag(dot_products)\n",
    "    sq_distances = -2 * dot_products + sq_norms[:, None] + sq_norms[None, :]\n",
    "    sq_median_distance = np.median(sq_distances)\n",
    "    return np.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))\n",
    "\n",
    "\n",
    "def gram_rbf_tf(x, threshold=1.0):\n",
    "    \"\"\"tensorflow version of gram_rbf\"\"\"\n",
    "    dot_products = tf.matmul(x, tf.transpose(x))\n",
    "    sq_norms = tf.matrix_diag_part(dot_products)\n",
    "    sq_distances = -2 * dot_products + tf.reshape(sq_norms, [-1, 1]) + tf.reshape(sq_norms, [1, -1])\n",
    "    temp = tfp.stats.percentile(sq_distances, 50., interpolation='lower')\n",
    "    temp += tfp.stats.percentile(sq_distances, 50., interpolation='higher')\n",
    "    sq_median_distance = temp / 2.\n",
    "    return tf.math.exp(-sq_distances / (2 * threshold ** 2 * sq_median_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 03:30:50.901623 140462725011264 deprecation.py:323] From /home/youngbin/anaconda3/envs/sle/lib/python3.6/site-packages/tensorflow_probability/python/stats/quantiles.py:608: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# check sameness\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "X_tf = tf.constant(X)\n",
    "\n",
    "gram_rbf_X = gram_rbf(X)\n",
    "gram_rbf_X_tf = gram_rbf_tf(X_tf).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(gram_rbf_X, gram_rbf_X_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_gram(gram, unbiased=False):\n",
    "    \"\"\"Center a symmetric Gram matrix.\n",
    "\n",
    "    This is equvialent to centering the (possibly infinite-dimensional) features\n",
    "    induced by the kernel before computing the Gram matrix.\n",
    "\n",
    "    Args:\n",
    "        gram: A num_examples x num_examples symmetric matrix.\n",
    "        unbiased: Whether to adjust the Gram matrix in order to compute an unbiased\n",
    "             estimate of HSIC. Note that this estimator may be negative.\n",
    "\n",
    "    Returns:\n",
    "        A symmetric matrix with centered columns and rows.\n",
    "    \"\"\"\n",
    "    if not np.allclose(gram, gram.T):\n",
    "        raise ValueError('Input must be a symmetric matrix.')\n",
    "    gram = gram.copy()\n",
    "\n",
    "    if unbiased:\n",
    "        # This formulation of the U-statistic, from Szekely, G. J., & Rizzo, M.\n",
    "        # L. (2014). Partial distance correlation with methods for dissimilarities.\n",
    "        # The Annals of Statistics, 42(6), 2382-2412, seems to be more numerically\n",
    "        # stable than the alternative from Song et al. (2007).\n",
    "        n = gram.shape[0]\n",
    "        np.fill_diagonal(gram, 0)\n",
    "        means = np.sum(gram, 0, dtype=np.float64) / (n - 2)\n",
    "        means -= np.sum(means) / (2 * (n - 1))\n",
    "        gram -= means[:, None]\n",
    "        gram -= means[None, :]\n",
    "        np.fill_diagonal(gram, 0)\n",
    "    else:\n",
    "        means = np.mean(gram, 0, dtype=np.float64)\n",
    "        means -= np.mean(means) / 2\n",
    "        gram -= means[:, None]\n",
    "        gram -= means[None, :]\n",
    "\n",
    "    return gram\n",
    "\n",
    "        \n",
    "def center_gram_tf(gram, unbiased=False):\n",
    "    \"\"\"tensorflow version of center_gram\"\"\"\n",
    "    gram = tf.identity(gram)\n",
    "    if unbiased:\n",
    "        n = gram.get_shape().as_list()[0]\n",
    "        gram = tf.matrix_set_diag(gram, tf.zeros(gram.shape[0:-1], tf.dtypes.float64))\n",
    "        means = tf.math.reduce_sum(gram, 0) / (n - 2)\n",
    "        means -= tf.math.reduce_sum(means) / (2 * (n - 1))\n",
    "        gram -= tf.reshape(means, [-1, 1])\n",
    "        gram -= tf.reshape(means, [1, -1])\n",
    "        gram = tf.matrix_set_diag(gram, tf.zeros(gram.shape[0:-1], tf.dtypes.float64))\n",
    "    else:\n",
    "        means = tf.math.reduce_mean(gram, 0)\n",
    "        means -= tf.math.reduce_mean(means) / 2\n",
    "        gram -= tf.reshape(means, [-1, 1])\n",
    "        gram -= tf.reshape(means, [1, -1])\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check sameness\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "X_tf = tf.constant(X)\n",
    "\n",
    "X_gram = gram_linear(X)\n",
    "X_gram_tf = gram_linear_tf(X_tf)\n",
    "\n",
    "center_gram_X = center_gram(X_gram)\n",
    "center_gram_X_tf = center_gram_tf(X_gram_tf).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(center_gram_X, center_gram_X_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cka(gram_x, gram_y, debiased=False):\n",
    "    \"\"\"Compute CKA.\n",
    "\n",
    "    Args:\n",
    "        gram_x: A num_examples x num_examples Gram matrix.\n",
    "        gram_y: A num_examples x num_examples Gram matrix.\n",
    "        debiased: Use unbiased estimator of HSIC. CKA may still be biased.\n",
    "\n",
    "    Returns:\n",
    "        The value of CKA between X and Y.\n",
    "    \"\"\"\n",
    "    gram_x = center_gram(gram_x, unbiased=debiased)\n",
    "    gram_y = center_gram(gram_y, unbiased=debiased)\n",
    "\n",
    "    # Note: To obtain HSIC, this should be divided by (n-1)**2 (biased variant) or\n",
    "    # n*(n-3) (unbiased variant), but this cancels for CKA.\n",
    "    scaled_hsic = gram_x.ravel().dot(gram_y.ravel())\n",
    "\n",
    "    normalization_x = np.linalg.norm(gram_x)\n",
    "    normalization_y = np.linalg.norm(gram_y)\n",
    "    return scaled_hsic / (normalization_x * normalization_y)\n",
    "\n",
    "def cka_tf(gram_x, gram_y, debiased=False):\n",
    "    \"\"\"tensorflow version of CKA(Centered Kernel Alignment)\"\"\"\n",
    "    gram_x = center_gram_tf(gram_x, unbiased=debiased)\n",
    "    gram_y = center_gram_tf(gram_y, unbiased=debiased)\n",
    "    \n",
    "    scaled_hsic = tf.tensordot(tf.reshape(gram_x, [-1]), tf.reshape(gram_y, [-1]), axes=1)\n",
    "    \n",
    "    normalization_x = tf.norm(gram_x, axis=[-2, -1])\n",
    "    normalization_y = tf.norm(gram_y, axis=[-2, -1])\n",
    "    return scaled_hsic / (normalization_x * normalization_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sameness\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "Y = np.random.randn(100, 10) + X\n",
    "X_tf = tf.constant(X)\n",
    "Y_tf = tf.constant(Y)\n",
    "\n",
    "CKA = cka(gram_linear(X), gram_linear(Y))\n",
    "CKA_tf = cka_tf(gram_linear_tf(X_tf), gram_linear_tf(Y_tf)).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(CKA, CKA_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _debiased_dot_product_similarity_helper(\n",
    "    xty, sum_squared_rows_x, sum_squared_rows_y, squared_norm_x, squared_norm_y, n):\n",
    "    \"\"\"Helper for computing debiased dot product similarity (i.e. linear HSIC).\"\"\"\n",
    "    # This formula can be derived by manipulating the unbiased estimator from\n",
    "    # Song et al. (2007).\n",
    "    return (xty - n / (n - 2.) * sum_squared_rows_x.dot(sum_squared_rows_y)\n",
    "            + squared_norm_x * squared_norm_y / ((n - 1) * (n - 2)))\n",
    "\n",
    "def feature_space_linear_cka(features_x, features_y, debiased=False):\n",
    "    \"\"\"Compute CKA with a linear kernel, in feature space.\n",
    "\n",
    "    This is typically faster than computing the Gram matrix when there are fewer\n",
    "    features than examples.\n",
    "\n",
    "    Args:\n",
    "        features_x: A num_examples x num_features matrix of features.\n",
    "        features_y: A num_examples x num_features matrix of features.\n",
    "        debiased: Use unbiased estimator of dot product similarity. CKA may still be\n",
    "          biased. Note that this estimator may be negative.\n",
    "\n",
    "    Returns:\n",
    "        The value of CKA between X and Y.\n",
    "    \"\"\"\n",
    "    features_x = features_x - np.mean(features_x, 0, keepdims=True)\n",
    "    features_y = features_y - np.mean(features_y, 0, keepdims=True)\n",
    "\n",
    "    dot_product_similarity = np.linalg.norm(features_x.T.dot(features_y)) ** 2\n",
    "    normalization_x = np.linalg.norm(features_x.T.dot(features_x))\n",
    "    normalization_y = np.linalg.norm(features_y.T.dot(features_y))\n",
    "\n",
    "    if debiased:\n",
    "        n = features_x.shape[0]\n",
    "        # Equivalent to np.sum(features_x ** 2, 1) but avoids an intermediate array.\n",
    "        sum_squared_rows_x = np.einsum('ij,ij->i', features_x, features_x)\n",
    "        sum_squared_rows_y = np.einsum('ij,ij->i', features_y, features_y)\n",
    "        squared_norm_x = np.sum(sum_squared_rows_x)\n",
    "        squared_norm_y = np.sum(sum_squared_rows_y)\n",
    "\n",
    "        dot_product_similarity = _debiased_dot_product_similarity_helper(\n",
    "            dot_product_similarity, sum_squared_rows_x, sum_squared_rows_y,\n",
    "            squared_norm_x, squared_norm_y, n)\n",
    "        normalization_x = np.sqrt(_debiased_dot_product_similarity_helper(\n",
    "            normalization_x ** 2, sum_squared_rows_x, sum_squared_rows_x,\n",
    "            squared_norm_x, squared_norm_x, n))\n",
    "        normalization_y = np.sqrt(_debiased_dot_product_similarity_helper(\n",
    "            normalization_y ** 2, sum_squared_rows_y, sum_squared_rows_y,\n",
    "            squared_norm_y, squared_norm_y, n))\n",
    "\n",
    "    return dot_product_similarity / (normalization_x * normalization_y)\n",
    "\n",
    "\n",
    "def _debiased_dot_product_similarity_helper_tf(\n",
    "    xty, sum_squared_rows_x, sum_squared_rows_y, squared_norm_x, squared_norm_y, n):\n",
    "    \"\"\"tensorflow version of _debiased_dot_product_similarity_helper\"\"\"\n",
    "    return (xty - n / (n - 2.) * tf.tensordot(sum_squared_rows_x, sum_squared_rows_y, axes=1)\n",
    "            + squared_norm_x * squared_norm_y / ((n - 1) * (n - 2)))\n",
    "\n",
    "def feature_space_linear_cka_tf(features_x, features_y, debiased=False):\n",
    "    \"\"\"tensorflow version of feature_space_linear_cka\"\"\"\n",
    "    features_x = features_x - tf.math.reduce_mean(features_x, 0, keepdims=True)\n",
    "    features_y = features_y - tf.math.reduce_mean(features_y, 0, keepdims=True)\n",
    "\n",
    "    dot_product_similarity = tf.pow(tf.norm(tf.matmul(tf.transpose(features_x), features_y)), 2)\n",
    "    normalization_x = tf.norm(tf.matmul(tf.transpose(features_x), features_x), axis=[-2, -1])\n",
    "    normalization_y = tf.norm(tf.matmul(tf.transpose(features_y), features_y), axis=[-2, -1])\n",
    "\n",
    "    if debiased:\n",
    "        n = features_x.get_shape().as_list()[0]\n",
    "        sum_squared_rows_x = tf.einsum('ij,ij->i', features_x, features_x)\n",
    "        sum_squared_rows_y = tf.einsum('ij,ij->i', features_y, features_y)\n",
    "        squared_norm_x = tf.math.reduce_sum(sum_squared_rows_x)\n",
    "        squared_norm_y = tf.math.reduce_sum(sum_squared_rows_y)\n",
    "\n",
    "        dot_product_similarity = _debiased_dot_product_similarity_helper_tf(\n",
    "            dot_product_similarity, sum_squared_rows_x, sum_squared_rows_y,\n",
    "            squared_norm_x, squared_norm_y, n)\n",
    "        normalization_x = tf.math.sqrt(_debiased_dot_product_similarity_helper_tf(\n",
    "            tf.pow(normalization_x, 2), sum_squared_rows_x, sum_squared_rows_x,\n",
    "            squared_norm_x, squared_norm_x, n))\n",
    "        normalization_y = tf.math.sqrt(_debiased_dot_product_similarity_helper_tf(\n",
    "            tf.pow(normalization_y, 2), sum_squared_rows_y, sum_squared_rows_y,\n",
    "            squared_norm_y, squared_norm_y, n))\n",
    "\n",
    "    return dot_product_similarity / (normalization_x * normalization_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check sameness\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "Y = np.random.randn(100, 10) + X\n",
    "X_tf = tf.constant(X)\n",
    "Y_tf = tf.constant(Y)\n",
    "\n",
    "cka_from_features_debiased = feature_space_linear_cka(X, Y, debiased=True)\n",
    "cka_from_features_debiased_tf = feature_space_linear_cka_tf(X_tf, Y_tf, debiased=True).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(cka_from_features_debiased, cka_from_features_debiased_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca(features_x, features_y):\n",
    "    \"\"\"Compute the mean squared CCA correlation (R^2_{CCA}).\n",
    "\n",
    "    Args:\n",
    "        features_x: A num_examples x num_features matrix of features.\n",
    "        features_y: A num_examples x num_features matrix of features.\n",
    "\n",
    "    Returns:\n",
    "        The mean squared CCA correlations between X and Y.\n",
    "    \"\"\"\n",
    "    qx, _ = np.linalg.qr(features_x)  # Or use SVD with full_matrices=False.\n",
    "    qy, _ = np.linalg.qr(features_y)\n",
    "    return np.linalg.norm(qx.T.dot(qy)) ** 2 / min(features_x.shape[1], features_y.shape[1])\n",
    "\n",
    "\n",
    "def cca_tf(features_x, features_y):\n",
    "    \"\"\"tensorflow version of cca(Canonical Correlation Analysis)\"\"\"\n",
    "    qx, _ = tf.linalg.qr(features_x)\n",
    "    qy, _ = tf.linalg.qr(features_y)\n",
    "    dimx = features_x.get_shape().as_list()[1]\n",
    "    dimy = features_y.get_shape().as_list()[1]\n",
    "    demoninator = tf.dtypes.cast(tf.math.minimum(dimx, dimy), tf.float64)\n",
    "    return tf.pow(tf.norm(tf.matmul(tf.transpose(qx), qy)), 2) / demoninator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sameness\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(1337)\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = np.random.randn(100, 10)\n",
    "Y = np.random.randn(100, 10) + X\n",
    "X_tf = tf.constant(X)\n",
    "Y_tf = tf.constant(Y)\n",
    "\n",
    "CCA = cca(X, Y)\n",
    "CCA_tf = cca_tf(X_tf, Y_tf).eval()\n",
    "\n",
    "np.testing.assert_almost_equal(CCA, CCA_tf)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "X = np.random.randn(100, 10)\n",
    "Y = np.random.randn(100, 10) + X\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X_tf = tf.constant(X)\n",
    "Y_tf = tf.constant(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA from Examples: 0.55761\n",
      "Linear CKA from Features: 0.55761\n"
     ]
    }
   ],
   "source": [
    "cka_from_examples = cka_tf(gram_linear_tf(X_tf), gram_linear_tf(Y_tf)).eval()\n",
    "cka_from_features = feature_space_linear_cka_tf(X_tf, Y_tf).eval()\n",
    "\n",
    "print('Linear CKA from Examples: {:.5f}'.format(cka_from_examples))\n",
    "print('Linear CKA from Features: {:.5f}'.format(cka_from_features))\n",
    "np.testing.assert_almost_equal(cka_from_examples, cka_from_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF CKA: 0.65483\n"
     ]
    }
   ],
   "source": [
    "rbf_cka = cka_tf(gram_rbf_tf(X_tf, 0.5), gram_rbf_tf(Y_tf, 0.5)).eval()\n",
    "print('RBF CKA: {:.5f}'.format(rbf_cka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA from Examples (Debiased): 0.51346\n",
      "Linear CKA from Features (Debiased): 0.51346\n"
     ]
    }
   ],
   "source": [
    "cka_from_examples_debiased = cka_tf(gram_linear_tf(X_tf), gram_linear_tf(Y_tf), debiased=True).eval()\n",
    "cka_from_features_debiased = feature_space_linear_cka_tf(X_tf, Y_tf, debiased=True).eval()\n",
    "\n",
    "print('Linear CKA from Examples (Debiased): {:.5f}'.format(cka_from_examples_debiased))\n",
    "print('Linear CKA from Features (Debiased): {:.5f}'.format(cka_from_features_debiased))\n",
    "np.testing.assert_almost_equal(cka_from_examples_debiased, cka_from_features_debiased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = np.random.randn(10, 10)\n",
    "transform_tf = tf.constant(transform)\n",
    "_, orthogonal_transform_tf = tf.linalg.eigh(gram_linear_tf(tf.transpose(transform_tf)))\n",
    "\n",
    "# CKA is invariant only to orthogonal transformations.\n",
    "np.testing.assert_almost_equal(\n",
    "    feature_space_linear_cka_tf(X_tf, Y_tf).eval(),\n",
    "    feature_space_linear_cka_tf(tf.matmul(X_tf, orthogonal_transform_tf), Y_tf).eval())\n",
    "np.testing.assert_(not np.isclose(\n",
    "    feature_space_linear_cka_tf(X_tf, Y_tf).eval(),\n",
    "    feature_space_linear_cka_tf(tf.matmul(X, transform_tf), Y_tf).eval()))\n",
    "\n",
    "# CCA is invariant to any invertible linear transform.\n",
    "np.testing.assert_almost_equal(cca_tf(X_tf, Y_tf).eval(),\n",
    "                               cca_tf(tf.matmul(X_tf, orthogonal_transform_tf), Y_tf).eval())\n",
    "np.testing.assert_almost_equal(cca_tf(X_tf, Y_tf).eval(),\n",
    "                               cca_tf(tf.matmul(X_tf, transform_tf), Y_tf).eval())\n",
    "\n",
    "# Both CCA and CKA are invariant to isotropic scaling.\n",
    "np.testing.assert_almost_equal(cca_tf(X_tf, Y_tf).eval(), cca_tf(X_tf * 1.337, Y_tf).eval())\n",
    "np.testing.assert_almost_equal(\n",
    "    feature_space_linear_cka_tf(X_tf, Y_tf).eval(),\n",
    "    feature_space_linear_cka_tf(X_tf * 1.337, Y_tf).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
