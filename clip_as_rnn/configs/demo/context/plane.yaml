# image_path: 'testcase/elon_mark.jpg'
# image_caption: ['person']
# image_caption: ['a photo of elon musk']

# image_path: '/homes/55/runjia/scratch/PASCAL_context/VOCdevkit/VOC2010/JPEGImages/2008_000002.jpg'
# image_path: '/homes/55/runjia/scratch/PASCAL_context/VOCdevkit/VOC2010/JPEGImages/2009_004592.jpg'
image_path: '/homes/55/runjia/scratch/PASCAL_context/VOCdevkit/VOC2010/JPEGImages/2009_004601.jpg'
# image_caption: ['airplane', 'bag', 'bed', 'bedclothes', 'bench', 'bicycle', 'bird', 'boat', 'book',
#                'bottle', 'building', 'bus', 'cabinet', 'car', 'cat', 'ceiling', 'chair', 'cloth', 'computer', 'cow',
#                'cup', 'curtain', 'dog', 'door', 'fence', 'floor', 'flower', 'food', 'grass', 'ground', 'horse',
#                'keyboard', 'light', 'motorbike', 'mountain', 'mouse', 'person', 'plate', 'platform', 'plant', 'road',
#                'rock', 'sheep', 'shelves', 'sidewalk', 'sign', 'sky', 'snow', 'sofa', 'table', 'track', 'train', 'tree',
#                'truck', 'monitor', 'wall', 'water', 'window', 'wood']

# image_caption: ['airplane', 'bag', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 
#                       'building', 'bus', 'cabinet', 'car', 'cat', 'chair', 'computer', 'cow', 'cup', 'dog', 
#                         'flower', 'food', 'horse', 'keyboard', 'motorbike', 'mouse', 'person', 'plate', 
#                       'plant', 'sheep', 'shelves', 'sign', 'sofa', 'table', 'track', 'train', 'tree', 'truck', 'monitor']

image_caption: ['plane']
stuff_caption: ['ground', 'sky']


clip:
  # clip_model_name: 'ViT-bigG-14'
  # semantic_clip_model_name: 'ViT-bigG-14'
  # semantic_pretrained_data: 'laion2b_s39b_b160k'
  semantic_clip_model_name: 'ViT-L/14'
  semantic_pretrained_data: 'openai'
  clip_model_name: "ViT-B/16"
  pretrained_data: 'openai'

  # clip_model: 'convnext_large_d_320'
  # pretrained_data: 'laion2b_s29b_b131k_ft_soup'
  # clip_model: 'convnext_xxlarge'
  # pretrained_data: 'laion2b_s34b_b82k_augreg_soup'
  # clip_model: 'ViT-L-14'
  # pretrained_data: 'openai'

cam:
  # layer_name: 'stages.3.blocks.2.norm'  # convnext
  layer_name: 'attn.dropout'
  clip_input_size: 224  # 320  # the input size of the image to clip model.
  dino_input_size: 480  # 512  # the input size of the image to SAM model.
  iom_thres: 0.5
  mask_threshold: 0.6
  num_layers: 1
  return_largest: False
  min_area_ratio: 0.2
  dino_device: 'cuda:0'
  return_confidence: True
  # cam_dino_arch: "base_v1"

camcut:
  dino_arch: "base_v1"
  tau: 0.15
  amplification_factor: 10
  attenuation_factor: 0.6
  instance_seg: False
  use_dino: True
  up_sample_rate: 4
  embedding_size: 1664
  binary_graph: False
  num_iteration: 1
  confidence_threshold: 0 # 0.2
  exclusive: False
  use_clip_es: True
  cam_mask_mutual_iou_thresh: 1
  alpha: 0.8
  num_diff_iterations: 0
  clipes_threshold: 0.4
  bg_factor: 1
  visual_prompt_type: ['blur', 'circle']
  # cam_text_template: 'a good photo of {}'
  semantic_templates: ['a clean origami {}.',
                        'a photo of a {}.',
                    'This is a photo of a {}',
                    'There is a {} in the scene',
                    'There is the {} in the scene',
                    'a photo of a {} in the scene',
                    'a photo of a small {}.',
                    'a photo of a medium {}.',
                    'a photo of a large {}.',
                    'This is a photo of a small {}.',
                    'This is a photo of a medium {}.',
                    'This is a photo of a large {}.',
                    'There is a small {} in the scene.',
                    'There is a medium {} in the scene.',
                    'There is a large {} in the scene.']


  bg_cls: ['ground', 'land', 'grass', 'tree', 'building',
            'wall', 'sky', 'lake', 'water', 'river', 'sea',
            'railway', 'railroad', 'helmet', 'cloud', 'house',
            'mountain', 'ocean', 'road', 'rock', 'street',
            'valley', 'bridge', 'bedclothes', 'building', 'ceiling', 
            'cloth', 'curtain', 'fence', 'floor', 'food', 'grass', 
            'ground', 'light', 'mountain', 'platform', 'road', 'rock', 
            'sidewalk', 'sign', 'sky', 'snow', 'track', 'wall', 'water', 
            'window', 'wood']
  


  stuff_bg_cls: ['airplane', 'bag', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 
                       'building', 'bus', 'cabinet', 'car', 'cat', 'chair', 'computer', 'cow', 'cup', 'dog', 
                         'flower', 'food', 'horse', 'keyboard', 'motorbike', 'mouse', 'person', 'plate', 
                       'plant', 'sheep', 'shelves', 'sign', 'sofa', 'table', 'track', 'train', 'tree', 'truck', 'monitor']
  


#   # SAM
#   # min_pred_threshold: 0.2
#   # points_per_side: 64
#   # pred_iou_thresh: 0.88
#   # stability_score_thresh: 0.95
#   # box_nms_thresh: 0.7
  

# sam_model:
#   model_dir: "/datasets/jianhaoy/Cache/SAM"
#   sam_checkpoint: "/storage2/jianhaoy/SAM/sam_hq_vit_h.pth"  #  "/storage2/jianhaoy/SAM/sam_hq_vit_h.pth"
#   model_type: "vit_h"
#   device: "cuda:0"
#   # device: "cpu"

sam:
  model_dir: "//homes/55/runjia/scratch/SAM/model_dir"
  sam_checkpoint: "/homes/55/runjia/scratch/SAM/model_dir/sam_hq_vit_h.pth"  #  "/storage2/jianhaoy/SAM/sam_hq_vit_h.pth"
  model_type: "vit_h"
  min_pred_threshold: 0.01
  points_per_side: 256
  pred_iou_thresh: 0.88
  stability_score_thresh: 0.9
  box_nms_thresh: 0.5


test:
  algo: "maskcut"
  ds_name: "context"
  seg_mode: "semantic"
  n_class: 60
    # data_root: "/home/lir0c/storage/PASCAL/"
  # data_root: "/datasets/jianhaoy/PASCAL/"
  data_root: "/homes/55/runjia/scratch/PASCAL_context"
  output_path: "./outputs/"
  prompts_augment: False
  prompts_prefix: False
  use_pseudo: True
  split: "val"
  # use_iterative: False
  num_iteration: 1

    

save_path: "./outputs"