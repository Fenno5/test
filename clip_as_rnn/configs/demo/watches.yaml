# image_path: 'testcase/elon_mark.jpg'
# image_caption: ['person']
# image_caption: ['a photo of elon musk']

# image_path: "testcase/voc_failure_case/cat.jpg"
# image_caption: ['person', 'cat', 'aeroplane', 'dog', 'chair']

# image_path: "testcase/voc_failure_case/dog.jpg"
# image_caption: ['person', 'cat', 'aeroplane', 'dog', 'chair']


# image_path: "testcase/voc_failure_case/bicycle.jpg"
# image_caption: ['person', 'cat', 'aeroplane', 'dog', 'chair', 'bicycle']

# image_path: "testcase/trump_xi.jpg"
# image_caption: ['donald trump', 'jinping xi']

image_path: "demo/watches1.jpg"
image_caption: ['Apple Watch', 'Rolex', 'Casio', 'Nomos', 'Grand Seiko']


# image_path: "testcase/voc_failure_case/bus.jpg"
# image_caption: ['person', 'cat', 'aeroplane', 'dog', 'chair', 'bicycle', 'bus']


# image_caption: ['dog']
# image_path: 'testcase/harry_potter.jpg'
# image_caption: ['ceo of facebook']
# image_caption: ['harry potter']
# image_caption: ['ron weasley']

# image_path: testcase/trump_xi.jpg
# image_caption: ['president of United States']

# image_path: 'testcase/weiweizhang.jpg'
# image_caption: ['weiwei zhang']

# image_path: 'testcase/indian_ceos.jpg'
# image_caption: ['Sundar Pichai']  # 'sundar pichai'


# image_path: "testcase/voc_plane.jpg"
# image_caption: ['aeroplane']
# background_caption: ['ground','land','grass','tree','building','wall','sky','lake','water','river','sea','railway','railroad','keyboard','helmet',
#                         'cloud','house','mountain','ocean','road','rock','street','valley','bridge','sign',
#                         ]


# image_path: "testcase/voc_train.jpg"
# image_caption: ['train']
# background_caption: ['ground','land','grass','tree','building','wall','sky','lake','water','river','sea','railway','railroad','keyboard','helmet',
#                         'cloud','house','mountain','ocean','road','rock','street','valley','bridge','sign',
#                         ]

# image_path: testcase/maskcut/COCO_train2014_000000563679.jpg
# image_caption: ['the middle zebra in the picture']

clip:
  # clip_model_name: 'ViT-bigG-14'
  # semantic_clip_model_name: 'ViT-bigG-14'
  # semantic_pretrained_data: 'laion2b_s39b_b160k'
  semantic_clip_model_name: 'ViT-L/14'
  semantic_pretrained_data: 'openai'
  clip_model_name: "ViT-B/16"
  pretrained_data: 'openai'

  # clip_model: 'convnext_large_d_320'
  # pretrained_data: 'laion2b_s29b_b131k_ft_soup'
  # clip_model: 'convnext_xxlarge'
  # pretrained_data: 'laion2b_s34b_b82k_augreg_soup'
  # clip_model: 'ViT-L-14'
  # pretrained_data: 'openai'

cam:
  # layer_name: 'stages.3.blocks.2.norm'  # convnext
  layer_name: 'attn.dropout'
  clip_input_size: 224  # 320  # the input size of the image to clip model.
  dino_input_size: 480  # 512  # the input size of the image to SAM model.
  iom_thres: 0.6
  mask_threshold: 0.5
  num_layers: 1
  return_largest: False
  min_area_ratio: 0.2
  dino_device: 'cuda:0'
  return_confidence: True
  # cam_dino_arch: "base_v1"

camcut:
  dino_arch: "base_v1"
  tau: 0.15
  amplification_factor: 10
  attenuation_factor: 0.7
  instance_seg: False
  use_dino: True
  up_sample_rate: 4
  embedding_size: 1664
  binary_graph: False
  confidence_threshold: 0 # 0.2
  exclusive: False
  use_clip_es: True
  cam_mask_mutual_iou_thresh: 1
  alpha: 0.8
  clipes_threshold: 0.9
  visual_prompt_type: ['gray', 'blur']
  semantic_templates: ['a clean origami {}.',
                        'a photo of a {}.',
                    'This is a photo of a {}',
                    'There is a {} in the scene',
                    'There is the {} in the scene',
                    'a photo of a {} in the scene',
                    'a photo of a small {}.',
                    'a photo of a medium {}.',
                    'a photo of a large {}.',
                    'This is a photo of a small {}.',
                    'This is a photo of a medium {}.',
                    'This is a photo of a large {}.',
                    'There is a small {} in the scene.',
                    'There is a medium {} in the scene.',
                    'There is a large {} in the scene.']
  bg_cls: ['ground', 'land', 'grass', 'tree', 'building',
            'wall', 'sky', 'lake', 'water', 'river', 'sea',
            'railway', 'railroad', 'helmet', 'cloud', 'house',
            'mountain', 'ocean', 'road', 'rock', 'street',
            'valley', 'bridge']
#   # SAM
#   # min_pred_threshold: 0.2
#   # points_per_side: 64
#   # pred_iou_thresh: 0.88
#   # stability_score_thresh: 0.95
#   # box_nms_thresh: 0.7
  

sam:
  model_dir: "//homes/55/runjia/scratch/SAM/model_dir"
  sam_checkpoint: "/homes/55/runjia/scratch/SAM/model_dir/sam_hq_vit_h.pth"  #  "/storage2/jianhaoy/SAM/sam_hq_vit_h.pth"
  model_type: "vit_h"
  min_pred_threshold: 0.05
  points_per_side: 64
  pred_iou_thresh: 0.88
  stability_score_thresh: 0.9
  box_nms_thresh: 0.7



test:
  confidence_threshold: 0.7
  algo: "maskcut"
  ds_name: "voc"
  seg_mode: "semantic"
  split: 'val'
  # data_root: "/home/lir0c/storage/PASCAL/"
  # data_root: "/datasets/jianhaoy/PASCAL/"
  data_root: "/homes/55/runjia/scratch/PASCAL/"
  sam_mask_root: "/homes/55/runjia/scratch/SAM_masks/VOC"
  output_path: "./outputs/"
  prompts_augment: False
  prompts_prefix: False
  use_pseudo: True
  # use_iterative: False
  num_iteration: 1
  use_background: False
  label_space:
    voc: [
            'Aero plane',
            'Bicycle',
            'Bird',
            'Boat',
            'Bottle',
            'Bus',
            'Car',
            'Cat',
            'Chair',
            'Cow',
            'Dining table',
            'Dog',
            'Horse',
            'Motorbike',
            'Person',
            'Potted plant',
            'Sheep',
            'Sofa',
            'Train',
            'Tv/Monitor'
        ]
    
solver:
  lr: 0.0005
  weight_decay: 0.05
  batch_size: 6
  dice_ratio: 0
  bce_ratio: 1
  epoch: 100
  min_lr: 0.00001
  warmup_steps: 200
  min_area_ratio: 0.02
  multilabel: False
  use_droploss: True
  use_moving_average_loss: False
  use_cascade_camcut: False
  use_random_crop: True
  feat_size: 16


sentence_process:
  mixing_alpha: 0.2

cam_memory:
  enable: True

inference_length: 100

save_path: "./outputs"